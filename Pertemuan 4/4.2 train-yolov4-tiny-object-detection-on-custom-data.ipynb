{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "# 2 Train Yolo V4 Tiny using Custom Dataset & Darknet Framework\n",
        "- Setting GPU Environment\n",
        "- Installing Darknet for YOLOv4 on Colab\n",
        "- Download Dataset from Roboflow (previous notebook)\n",
        "- Train Custom YOLOv4 Detector\n",
        "- Infer Custom Objects with Saved YOLOv4 Weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è *Please open this notebook in Google Colab* by click below link ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è<br><br>\n",
        "<a href=\"https://colab.research.google.com/github/Muhammad-Yunus/Belajar-OpenCV-ObjectDetection/blob/main/Pertemuan%204/4.2 train-yolov4-tiny-object-detection-on-custom-data.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNVU7eu9CQj3"
      },
      "source": [
        "### 2.1 Connect GPU Environment \n",
        "\n",
        "- Click `Connect` button in top right Google Colab notebook,<br>\n",
        "<img src=\"resource/cl-connect-gpu.png\" width=\"250px\">\n",
        "- If connecting process completed, it will turn to something look like this<br>\n",
        "<img src=\"resource/cl-connect-gpu-success.png\" width=\"250px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDTvGt2zt7cm"
      },
      "source": [
        "- Configuring cuDNN on Colab for YOLOv4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-bguKWgtxSx",
        "outputId": "a481f773-9f9e-491c-f244-3cf210bbc187"
      },
      "outputs": [],
      "source": [
        "# CUDA: Let's check that Nvidia CUDA drivers are already pre-installed and which version is it.\n",
        "!/usr/local/cuda/bin/nvcc --version\n",
        "# We need to install the correct cuDNN according to this output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6BRAVo182G5",
        "outputId": "1e12e1ad-06f1-4990-b34b-8edbb7efb75a"
      },
      "outputs": [],
      "source": [
        "#take a look at the kind of GPU we have\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fb5mFF-RyBAL",
        "outputId": "3374c140-067a-4453-a787-b02a94cc818d"
      },
      "outputs": [],
      "source": [
        "# This cell ensures you have the correct architecture for your respective GPU\n",
        "# If you command is not found, look through these GPUs, find the respective\n",
        "# GPU and add them to the archTypes dictionary\n",
        "\n",
        "import os\n",
        "os.environ['GPU_TYPE'] = str(os.popen('nvidia-smi --query-gpu=name --format=csv,noheader').read())\n",
        "\n",
        "def getGPUArch(argument):\n",
        "  try:\n",
        "    argument = argument.strip()\n",
        "    # All Colab GPUs\n",
        "    archTypes = {\n",
        "        \"Tesla V100-SXM2-16GB\": \"-gencode arch=compute_70,code=[sm_70,compute_70]\",\n",
        "        \"Tesla K80\": \"-gencode arch=compute_37,code=sm_37\",\n",
        "        \"Tesla T4\": \"-gencode arch=compute_75,code=[sm_75,compute_75]\",\n",
        "        \"Tesla P40\": \"-gencode arch=compute_61,code=sm_61\",\n",
        "        \"Tesla P4\": \"-gencode arch=compute_61,code=sm_61\",\n",
        "        \"Tesla P100-PCIE-16GB\": \"-gencode arch=compute_60,code=sm_60\"\n",
        "\n",
        "      }\n",
        "    return archTypes[argument]\n",
        "  except KeyError:\n",
        "    return \"GPU must be added to GPU Commands\"\n",
        "os.environ['ARCH_VALUE'] = getGPUArch(os.environ['GPU_TYPE'])\n",
        "\n",
        "print(\"GPU Type: \" + os.environ['GPU_TYPE'])\n",
        "print(\"ARCH Value: \" + os.environ['ARCH_VALUE'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16pvdFMa1FEe"
      },
      "source": [
        "### 2.2 Installing Darknet for YOLOv4 on Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9uY-38P93oz",
        "outputId": "2de2ac90-8240-4cb6-bce4-36350be47c86"
      },
      "outputs": [],
      "source": [
        "%cd /content/\n",
        "%rm -rf darknet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQEktcfj9y9O",
        "outputId": "3586b7c3-83b5-43cb-c383-54e0da0ab583"
      },
      "outputs": [],
      "source": [
        "#we clone the fork of darknet maintained by roboflow\n",
        "#small changes have been made to configure darknet for training\n",
        "!git clone https://github.com/AlexeyAB/darknet.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyMBDkaL-Aep",
        "outputId": "dd6baeda-8504-4b54-b11b-ece73f16b755"
      },
      "outputs": [],
      "source": [
        "#install environment from the Makefile\n",
        "%cd /content/darknet/\n",
        "\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/g' Makefile\n",
        "!sed -i 's/GPU=0/GPU=1/g' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/g' Makefile\n",
        "!sed -i \"s/ARCH= -gencode arch=compute_60,code=sm_60/ARCH= ${ARCH_VALUE}/g\" Makefile\n",
        "!make"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGPDEjfAALrQ",
        "outputId": "f4ca5a57-db48-4e71-cecb-5669b806aada"
      },
      "outputs": [],
      "source": [
        "#download the newly released yolov4-tiny weights for transfer learning\n",
        "%cd /content/darknet\n",
        "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.weights\n",
        "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.conv.29"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWOiKj37l4wW"
      },
      "source": [
        "### 2.3 Download Dataset from Roboflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbniFj-eSimL"
      },
      "source": [
        "- Back to `Roboflow` > `Project` > `Versions` menu\n",
        "- Then click `Download Dataset`<br>\n",
        "<img src=\"resource/rb-download-dataset.png\" width=\"850px\">\n",
        "- Choose `YOLO Darknet` format and select `Show download code` then click `Continue` <br>\n",
        "<img src=\"resource/rb-download-format.png\" width=\"350px\">\n",
        "- click `Copy` icon to copy roboflow download code<br>\n",
        "<img src=\"resource/rb-copy-download-code.png\" width=\"350px\">\n",
        "- Then replace below code using the copied roboflow download code above,\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cdj4tmT5Cmdl",
        "outputId": "3a4aa613-d2b4-45ec-a34a-b0dd165ebfaa"
      },
      "outputs": [],
      "source": [
        "# !pip install roboflow\n",
        "\n",
        "# from roboflow import Roboflow\n",
        "# rf = Roboflow(api_key=\"xxxxxxxxxxxxx\")\n",
        "# project = rf.workspace(\"xxxxxxxxxxxxxxxx\").project(\"xxxxxxxxxxxxxxxxxxxx\")\n",
        "# version = project.version(1)\n",
        "# dataset = version.download(\"darknet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Set up training file directories for custom dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiCILEbs1NII",
        "outputId": "676ef3e0-939b-4b11-b739-b544449f4e2a"
      },
      "outputs": [],
      "source": [
        "%cd /content/darknet/\n",
        "%cp {dataset.location}/train/_darknet.labels data/obj.names\n",
        "%mkdir data/obj\n",
        "#copy image and labels\n",
        "%cp {dataset.location}/train/*.jpg data/obj/\n",
        "%cp {dataset.location}/valid/*.jpg data/obj/\n",
        "\n",
        "%cp {dataset.location}/train/*.txt data/obj/\n",
        "%cp {dataset.location}/valid/*.txt data/obj/\n",
        "\n",
        "with open('data/obj.data', 'w') as out:\n",
        "  out.write('classes = 3\\n')\n",
        "  out.write('train = data/train.txt\\n')\n",
        "  out.write('valid = data/valid.txt\\n')\n",
        "  out.write('names = data/obj.names\\n')\n",
        "  out.write('backup = backup/')\n",
        "\n",
        "#write train file (just the image list)\n",
        "import os\n",
        "\n",
        "with open('data/train.txt', 'w') as out:\n",
        "  for img in [f for f in os.listdir(dataset.location + '/train') if f.endswith('jpg')]:\n",
        "    out.write('data/obj/' + img + '\\n')\n",
        "\n",
        "#write the valid file (just the image list)\n",
        "import os\n",
        "\n",
        "with open('data/valid.txt', 'w') as out:\n",
        "  for img in [f for f in os.listdir(dataset.location + '/valid') if f.endswith('jpg')]:\n",
        "    out.write('data/obj/' + img + '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HtRqO3QvjkP"
      },
      "source": [
        "- Write Custom Training Config for YOLOv4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_WJcqHhpeVr",
        "outputId": "e3fbdebc-df7a-4631-9dec-df274aa22578"
      },
      "outputs": [],
      "source": [
        "#we build config dynamically based on number of classes\n",
        "#we build iteratively from base config files. This is the same file shape as cfg/yolo-obj.cfg\n",
        "def file_len(fname):\n",
        "  with open(fname) as f:\n",
        "    for i, l in enumerate(f):\n",
        "      pass\n",
        "  return i + 1\n",
        "\n",
        "num_classes = file_len(dataset.location + '/train/_darknet.labels')\n",
        "max_batches = num_classes*2000\n",
        "steps1 = .8 * max_batches\n",
        "steps2 = .9 * max_batches\n",
        "steps_str = str(steps1)+','+str(steps2)\n",
        "num_filters = (num_classes + 5) * 3\n",
        "\n",
        "\n",
        "print(\"writing config for a custom YOLOv4 detector detecting number of classes: \" + str(num_classes))\n",
        "\n",
        "#Instructions from the darknet repo\n",
        "#change line max_batches to (classes*2000 but not less than number of training images, and not less than 6000), f.e. max_batches=6000 if you train for 3 classes\n",
        "#change line steps to 80% and 90% of max_batches, f.e. steps=4800,5400\n",
        "if os.path.exists('./cfg/custom-yolov4-tiny-detector.cfg'): os.remove('./cfg/custom-yolov4-tiny-detector.cfg')\n",
        "\n",
        "\n",
        "#customize iPython writefile so we can write variables\n",
        "from IPython.core.magic import register_line_cell_magic\n",
        "\n",
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "03VuD4NHnxFx"
      },
      "outputs": [],
      "source": [
        "%%writetemplate ./cfg/custom-yolov4-tiny-detector.cfg\n",
        "[net]\n",
        "# Testing\n",
        "#batch=1\n",
        "#subdivisions=1\n",
        "# Training\n",
        "batch=64\n",
        "subdivisions=24\n",
        "width=416\n",
        "height=416\n",
        "channels=3\n",
        "momentum=0.9\n",
        "decay=0.0005\n",
        "angle=0\n",
        "saturation = 1.5\n",
        "exposure = 1.5\n",
        "hue=.1\n",
        "\n",
        "learning_rate=0.00261\n",
        "burn_in=1000\n",
        "max_batches = {max_batches}\n",
        "policy=steps\n",
        "steps={steps_str}\n",
        "scales=.1,.1\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=32\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers=-1\n",
        "groups=2\n",
        "group_id=1\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=32\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=32\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers = -1,-2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers = -6,-1\n",
        "\n",
        "[maxpool]\n",
        "size=2\n",
        "stride=2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers=-1\n",
        "groups=2\n",
        "group_id=1\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers = -1,-2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers = -6,-1\n",
        "\n",
        "[maxpool]\n",
        "size=2\n",
        "stride=2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers=-1\n",
        "groups=2\n",
        "group_id=1\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers = -1,-2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers = -6,-1\n",
        "\n",
        "[maxpool]\n",
        "size=2\n",
        "stride=2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "##################################\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "filters={num_filters}\n",
        "activation=linear\n",
        "\n",
        "\n",
        "\n",
        "[yolo]\n",
        "mask = 3,4,5\n",
        "anchors = 10,14,  23,27,  37,58,  81,82,  135,169,  344,319\n",
        "classes={num_classes}\n",
        "num=6\n",
        "jitter=.3\n",
        "scale_x_y = 1.05\n",
        "cls_normalizer=1.0\n",
        "iou_normalizer=0.07\n",
        "iou_loss=ciou\n",
        "ignore_thresh = .7\n",
        "truth_thresh = 1\n",
        "random=0\n",
        "nms_kind=greedynms\n",
        "beta_nms=0.6\n",
        "\n",
        "[route]\n",
        "layers = -4\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[upsample]\n",
        "stride=2\n",
        "\n",
        "[route]\n",
        "layers = -1, 23\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "filters={num_filters}\n",
        "activation=linear\n",
        "\n",
        "[yolo]\n",
        "mask = 1,2,3\n",
        "anchors = 10,14,  23,27,  37,58,  81,82,  135,169,  344,319\n",
        "classes={num_classes}\n",
        "num=6\n",
        "jitter=.3\n",
        "scale_x_y = 1.05\n",
        "cls_normalizer=1.0\n",
        "iou_normalizer=0.07\n",
        "iou_loss=ciou\n",
        "ignore_thresh = .7\n",
        "truth_thresh = 1\n",
        "random=0\n",
        "nms_kind=greedynms\n",
        "beta_nms=0.6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWrG9EGamSpH"
      },
      "source": [
        "### 2.4 Train Custom YOLOv4 Detector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6miYFbvExqMd",
        "outputId": "09e09bca-3de0-46cf-9244-209857a32e13"
      },
      "outputs": [],
      "source": [
        "!./darknet detector train data/obj.data cfg/custom-yolov4-tiny-detector.cfg yolov4-tiny.conv.29 -dont_show -map\n",
        "#If you get CUDA out of memory adjust subdivisions above!\n",
        "#adjust max batches down for shorter training above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Original Yolo Tiny performance comparison <br>\n",
        "<img src=\"resource/map-yolo-tiny.png\" width=\"600px\"><br>\n",
        "*source : https://ietresearch.onlinelibrary.wiley.com/doi/pdf/10.1049/cvi2.12072*<br><br>\n",
        "- Improve mAP üìàüìàüìà \n",
        "    - **Add more data**, more data leads to better generalization. \n",
        "    - **Check annotated data**, check if annotation and label is correct.\n",
        "    - **Change Dataset resolution**, higer is better but longer time to complete the training process, original size 416x416.\n",
        "    - **Apply more Augmentation**, more diverse data often leads to better generalization.\n",
        "    - **Fixing Class Imbalance**, class imbalance will leading to false detection on other class with high accuracy in larger class only.\n",
        "    - **Change pretrained model**, change Yolo V4 tiny, to higer version e.g `Yolo V8`  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBnwpBV5ZXxQ"
      },
      "source": [
        "### 2.5 Infer Custom Objects with Saved YOLOv4 Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "FzoJQQw8Zdco"
      },
      "outputs": [],
      "source": [
        "#define utility function\n",
        "def imShow(path):\n",
        "  import cv2\n",
        "  import matplotlib.pyplot as plt\n",
        "  %matplotlib inline\n",
        "\n",
        "  image = cv2.imread(path)\n",
        "  height, width = image.shape[:2]\n",
        "  resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(6, 6)\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- check trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3dJB6NZv4kh",
        "outputId": "a2adad31-1da5-4665-91f8-ae8cfb7976bf"
      },
      "outputs": [],
      "source": [
        "%cd /content/darknet/\n",
        "!ls backup\n",
        "#if it is empty you haven't trained for long enough yet, you need to train for at least 100 iterations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "x-_E3O5Mf4Mf"
      },
      "outputs": [],
      "source": [
        "#coco.names is hardcoded somewhere in the detector\n",
        "%cp data/obj.names data/coco.names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NjKzw2TvZrOQ",
        "outputId": "5c0b3bfc-3835-4f6f-d7bf-926d3fb1aa1c"
      },
      "outputs": [],
      "source": [
        "#/test has images that we can test our detector on\n",
        "DATASET_FOLDER = \"Skissors-Detection-1\"  ## ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è CHANGE WITH THE CORRECT FOLDER NAME ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è\n",
        "\n",
        "test_images = [f for f in os.listdir(DATASET_FOLDER + '/test') if f.endswith('.jpg')]\n",
        "import random\n",
        "img_path = DATASET_FOLDER + '/test/' + random.choice(test_images);\n",
        "\n",
        "#test out our detector!\n",
        "!./darknet detect cfg/custom-yolov4-tiny-detector.cfg backup/custom-yolov4-tiny-detector_last.weights {img_path} -dont-show\n",
        "imShow('/content/darknet/predictions.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Download Trained Yolo V4 Tiny (`.cfg` & `.weights`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download ONNX the model.\n",
        "from google.colab import files\n",
        "files.download('cfg/custom-yolov4-tiny-detector.cfg')\n",
        "files.download('backup/custom-yolov4-tiny-detector_last.weights')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-------------------------------------------------------------\n",
        "### Source\n",
        "- Original Source [https://github.com/roboflow/notebooks/blob/main/notebooks/train-yolov4-tiny-object-detection-on-custom-data.ipynb](https://github.com/roboflow/notebooks/blob/main/notebooks/train-yolov4-tiny-object-detection-on-custom-data.ipynb)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
